<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>DiffSketching: Sketch Control Image Synthesis with Diffusion Models | kako</title><meta name="author" content="kako523"><meta name="copyright" content="kako523"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Abstract传统上，创建一个从草图到图像合成的深度学习模型需要克服没有视觉细节的扭曲输入草图，并且需要收集大规模的草图-图像数据集。我们首先使用扩散模型来研究这个任务。我们的模型通过跨域约束来匹配草图，并使用一个分类器来更准确地指导图像合成。大量的实验证实，我们的方法不仅可以忠实于用户输入的草图，而且还可以保持合成图像结果的多样性和想象力。我们的模型在生成质量和人工评价方面可以击败基于gan的">
<meta property="og:type" content="article">
<meta property="og:title" content="DiffSketching: Sketch Control Image Synthesis with Diffusion Models">
<meta property="og:url" content="http://example.com/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/index.html">
<meta property="og:site_name" content="kako">
<meta property="og:description" content="Abstract传统上，创建一个从草图到图像合成的深度学习模型需要克服没有视觉细节的扭曲输入草图，并且需要收集大规模的草图-图像数据集。我们首先使用扩散模型来研究这个任务。我们的模型通过跨域约束来匹配草图，并使用一个分类器来更准确地指导图像合成。大量的实验证实，我们的方法不仅可以忠实于用户输入的草图，而且还可以保持合成图像结果的多样性和想象力。我们的模型在生成质量和人工评价方面可以击败基于gan的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wallroom.io/img/3840x2160/bg-b158248.jpg">
<meta property="article:published_time" content="2023-01-26T02:37:49.000Z">
<meta property="article:modified_time" content="2023-02-05T13:56:37.313Z">
<meta property="article:author" content="kako523">
<meta property="article:tag" content="算法复现">
<meta property="article:tag" content="文献阅读">
<meta property="article:tag" content="diffusion">
<meta property="article:tag" content="图像生成">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wallroom.io/img/3840x2160/bg-b158248.jpg"><link rel="shortcut icon" href="/img/icon.jpg"><link rel="canonical" href="http://example.com/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DiffSketching: Sketch Control Image Synthesis with Diffusion Models',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-05 21:56:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="kako" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://wallroom.io/img/3840x2160/bg-b158248.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">kako</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DiffSketching: Sketch Control Image Synthesis with Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-26T02:37:49.000Z" title="发表于 2023-01-26 10:37:49">2023-01-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-05T13:56:37.313Z" title="更新于 2023-02-05 21:56:37">2023-02-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="DiffSketching: Sketch Control Image Synthesis with Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>传统上，创建一个从草图到图像合成的深度学习模型需要克服没有视觉细节的扭曲输入草图，并且需要收集大规模的草图-图像数据集。我们首先使用扩散模型来研究这个任务。我们的模型通过跨域约束来匹配草图，并使用一个<strong>分类器</strong>来更准确地指导图像合成。大量的实验证实，我们的方法不仅可以忠实于用户输入的草图，而且还可以保持合成图像结果的多样性和想象力。我们的模型在生成质量和人工评价方面可以击败基于gan的方法，<strong>并且不依赖于大量的素描图像数据集</strong>。此外，我们还介绍了我们的方法在图像编辑和插值中的应用。</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>扩散模型迅速流行起来，并在一些关键指标[10]中击败了GANs，为生成模型的研究带来了新的创造力。受此启发，我们提出了扩散素描，一种通过扩散模型的草图引导图像合成方法。通过前向扩散过程将输入图像转换为潜在噪声。在草图的指导下，调整分数功能，以转换为新的图像。这一过程不需要依赖于大型的草图-图像配对数据集，并且可以在定性比较和人工评价结果方面击败基于gan的方法。</p>
<p>我们的目标是，用户只需要输入一个草图，而我们的模型可以生成许多相应的图像。使用扩散模型来完成这一任务主要有三个挑战。</p>
<blockquote>
<ol>
<li><p>现有的扩散模型在单个领域内生成数据，因此我们需要一种合适的跨域生成的指导方法，以及一种合适的方法来度量两个不同领域内的数据分布。</p>
</li>
<li><p>与从图像中提取的边缘图不同，草图和相应的图像在空间和几何形状上更不一致，因此难以测量草图图像的跨域匹配。</p>
</li>
<li><p>用户输入的草图包含很少的信息，并且经常有歧义（例如，画一只狗，很难判断它是德国牧羊犬还是Briard）。我们需要引入更多的信息来消除这种歧义。</p>
</li>
</ol>
</blockquote>
<p>为了解决上述挑战，我们的工作做出了以下重大贡献。</p>
<blockquote>
<ol>
<li><p>我们提出了一个模型，它可以从单个草图中合成忠实的草图和真实的图像（图1），在基准测试上比基于gan的模型表现更好。</p>
</li>
<li><p>我们可以更精细地指导生成过程，消除了输入草图的奇异性和不确定性。</p>
</li>
<li><p>我们证明了我们的方法能够编辑图像，并在草图的条件下进行图像插值。</p>
</li>
</ol>
</blockquote>
<img src="https://i.328888.xyz/2023/02/04/NrdMV.png" alt="NrdMV.png" border="0" />

<h2 id="2-related-works"><a href="#2-related-works" class="headerlink" title="2 related works"></a>2 related works</h2><p>然而，扩散模型的一个显著缺点是，它模拟了马尔可夫链的多个时间步长来生成样本。除了DDIM之外，人们还提出了许多加速方法[28,37,44,53,58]。除了图像合成[2,38,39,42]外，扩散模型还广泛应用于图像到图像转换[8,31,54]、文本到图像转换[16,26,41,43]、视频生成[18,22,57]和音频生成[23,27,30]等各个领域。</p>
<h2 id="3-素描制导图像生成的扩散模型"><a href="#3-素描制导图像生成的扩散模型" class="headerlink" title="3 素描制导图像生成的扩散模型"></a>3 素描制导图像生成的扩散模型</h2><h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a><strong>4 Experiments</strong></h2><h3 id="4-1评估"><a href="#4-1评估" class="headerlink" title="4.1评估"></a>4.1评估</h3><p><strong>Datasets</strong>: 我们选择具有256×256分辨率的ImageNet数据集，包括1000个类别的128K图像，对类引导扩散模型进行预训练。在微调阶段，我们从素描[45]数据集中提取12.5K张图像，每个图像对应5张∼10幅草图。</p>
<p><strong>定量分析</strong>：我们基于弗雷切特初始距离[20]（<strong>FID</strong>）、初始距离评分[1]（<strong>IS</strong>）、精度和召回指标[29]来衡量我们的模型样本质量。FID通过比较图像特征的均值和方差来度量真实图像和生成图像之间的分布相似性。IS计算生成的图像分布的分类熵。精度度量的是模型样本在VGG特征空间[47]中接近数据样本的保真度，召回量的是VGG特征空间中数据样本接近模型样本的多样性。</p>
<p><strong>Human study</strong> ：我们通过比较不同基线方法的输出与我们的方法进行人工研究来判断合成质量。给定一个输入草图和不同方法的输出，参与者被要求选择在输出中最符合草图特征的图像。这次测试共招募了10名观众。我们随机抽取了500个样本进行随机显示。并计算每种选定方法的百分比。</p>
<h3 id="4-2-比较"><a href="#4-2-比较" class="headerlink" title="4.2 比较"></a><strong>4.2 比较</strong></h3><p><strong>Baselines</strong>：据我们所知，这是第一次将扩散模型用于基于草图的图像合成，并且之前的大部分工作都是基于GANs的。我们选择了3个基线模型，为了公平地说，所有的方法都在素描评估数据集上进行了测试。</p>
<blockquote>
<p>（1） USPS [35]是一个无监督的GAN模型，由两个步骤组成，将草图形状转换为灰度图像，并将其丰富为彩色图像。它提出了一个注意模块来处理抽象和风格的变化，可以提高生成的质量和真实性。</p>
<p>（2）MUNIT [24]是一个通用的无监督多模态图像转换框架。MUNIT将图像分解为内容代码和样式代码。它将内容代码与随机抽样的样式代码重新组合。并且该模型同时学习这两种代码。</p>
<p>（3）Sketch-YOG [52]预训练了一个基于gan的生成模型，利用跨域对抗性学习和图像空间调节来进行微调。</p>
</blockquote>
<p><strong>基准测试和定性分析结果</strong>：</p>
<p>（1）我们的模型在表1中列出的几乎所有指标上都优于其他基线，这表明我们可以以更多的多样性和高保真度恢复图像。人类研究得分越高，表明我们的综合结果更符合人类的直觉判断。</p>
<p>（2）与USPS和MUNIT不同，我们的模型没有需要大规模的素描图像数据集。由于缺乏如此大的数据集，许多基于gan的草图到图像模型只能合成一些类别，如鞋子和椅子。我们比较了对鞋的定性结果，如图3所示。</p>
<p>（3）USPS和MUNIT生成的图像形状与输入的草图严格匹配，它们专注于颜色、纹理和阴影的生成。而Sketch-YOG和我们的方法在外部轮廓方面给了模型更多的想象力，特别是我们能够生成更复杂的背景，从而产生更高的IS分数。</p>
<p>（4）精度略低于Sketch-YOG，说明我们的模型对真实数据分布的敏感性略低。更多的比较结果和分析可以在补充材料中找到。</p>
<h3 id="4-3-基于草图的图像合成"><a href="#4-3-基于草图的图像合成" class="headerlink" title="4.3 基于草图的图像合成"></a>4.3 基于草图的图像合成</h3><p><strong>细粒度草图控制图像合成：</strong>如图4(a)所示，当绘制一只狗时，用户的简单笔画不能被识别为德国牧羊犬、荆棘犬、瑞士山犬或任何其他类别。经过训练的分类器使用户能够在图4(b).中生成的类别更有趣的是，当我们指定与原始输入草图无关的类别时，我们仍然可以合成在样式和形状上与草图相似的图像，如图4(c).所示</p>
<p><strong>为了证明我们的模型比其他方法更实用</strong>，我们对手绘草图进行了测试。快速绘制[17]收集真实的手绘草图，这是简单的和扭曲的。定性和定量结果分别如图5和表1所示。由于我们计算的是草图的整体感知损失，而不是局部细节的一对一配对，我们的模型仍然可以从真实和扭曲的输入草图中生成用户的理想结果，仅略微减少定量指标。</p>
<h3 id="4-4-应用"><a href="#4-4-应用" class="headerlink" title="4.4 应用"></a>4.4 应用</h3><p>我们的模型可以在输入草图的指导下编辑原始图像，获得新的图像。我们使用Luhman等人[36]中的注意块来输入原始图像信息，保留图像的基本纹理和颜色信息。并根据用户输入的草图修改姿态和形状特征，合成出新的图像。计算结果如图6(a).所示关于该方法的细节见补充资料。</p>
<p>条件插值由于DDIM的一致性，我们使用球形线性[46]来组合不同的初始潜变量x (0) T和x (1) T，得到一个新的x (α) T。</p>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><p>我们提出了扩散绘制，第一个利用扩散模型的跨领域草图到图像的合成方法。我们的方法可以在匹配输入时进行自监督，克服了草图和生成器参数空间之间的大域差距。我们可以通过分类器来区分简单线条的草图，显示出较强的内容推理能力。并且扩散素描在许多关键指标上都优于基于gan的方法，获得了高质量和现实的结果。我们进一步展示了应用于其他任务的潜力，如图像编辑和条件插值。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">kako523</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/">http://example.com/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">kako</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E7%8E%B0/">算法复现</a><a class="post-meta__tags" href="/tags/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a><a class="post-meta__tags" href="/tags/diffusion/">diffusion</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/">图像生成</a></div><div class="post_share"><div class="social-share" data-image="https://wallroom.io/img/3840x2160/bg-b158248.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/01/27/Sketch-based-image-retrieval-via-siamese-convolutional-neural-network/"><img class="prev-cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Sketch-based image retrieval via siamese convolutional neural network</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/28/MUNIT%E5%A4%9A%E6%A8%A1%E6%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9B%BE%E6%83%B3%E5%88%B0%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><img class="next-cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MUNIT多模态无监督图想到图像转换论文阅读</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/04/A-Diffusion-ReFinement-Model-for-Sketch-to-Point-Modeling/" title="A Diffusion-ReFinement Model for Sketch-to-Point Modeling"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-04</div><div class="title">A Diffusion-ReFinement Model for Sketch-to-Point Modeling</div></div></a></div><div><a href="/2022/12/28/MUNIT%E5%A4%9A%E6%A8%A1%E6%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9B%BE%E6%83%B3%E5%88%B0%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="MUNIT多模态无监督图想到图像转换论文阅读"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-28</div><div class="title">MUNIT多模态无监督图想到图像转换论文阅读</div></div></a></div><div><a href="/2023/01/27/Sketch-based-image-retrieval-via-siamese-convolutional-neural-network/" title="Sketch-based image retrieval via siamese convolutional neural network"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-27</div><div class="title">Sketch-based image retrieval via siamese convolutional neural network</div></div></a></div><div><a href="/2022/12/12/DCNet%E7%AE%97%E6%B3%95%E5%A4%8D%E7%8E%B0%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/" title="DCNet算法复现过程记录"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-12</div><div class="title">DCNet算法复现过程记录</div></div></a></div><div><a href="/2022/12/12/ICME-2022-%E5%A4%A9%E6%B1%A0/" title="ICME-2022 天池"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-12</div><div class="title">ICME-2022 天池</div></div></a></div><div><a href="/2022/12/14/DeFRCN%E7%AE%97%E6%B3%95%E5%A4%8D%E7%8E%B0/" title="DeFRCN算法复现"><img class="cover" src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-14</div><div class="title">DeFRCN算法复现</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">kako523</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kako523"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">还有很多不足之处欢迎各位大佬指正</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Introduction"><span class="toc-number">2.</span> <span class="toc-text">1 Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-related-works"><span class="toc-number">2.1.</span> <span class="toc-text">2 related works</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%B4%A0%E6%8F%8F%E5%88%B6%E5%AF%BC%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%9A%84%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">3 素描制导图像生成的扩散模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Experiments"><span class="toc-number">2.3.</span> <span class="toc-text">4 Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1%E8%AF%84%E4%BC%B0"><span class="toc-number">2.3.1.</span> <span class="toc-text">4.1评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%AF%94%E8%BE%83"><span class="toc-number">2.3.2.</span> <span class="toc-text">4.2 比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%9F%BA%E4%BA%8E%E8%8D%89%E5%9B%BE%E7%9A%84%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90"><span class="toc-number">2.3.3.</span> <span class="toc-text">4.3 基于草图的图像合成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E5%BA%94%E7%94%A8"><span class="toc-number">2.3.4.</span> <span class="toc-text">4.4 应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BB%93%E8%AE%BA"><span class="toc-number">2.4.</span> <span class="toc-text">5 结论</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/04/A-Diffusion-ReFinement-Model-for-Sketch-to-Point-Modeling/" title="A Diffusion-ReFinement Model for Sketch-to-Point Modeling"><img src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A Diffusion-ReFinement Model for Sketch-to-Point Modeling"/></a><div class="content"><a class="title" href="/2023/02/04/A-Diffusion-ReFinement-Model-for-Sketch-to-Point-Modeling/" title="A Diffusion-ReFinement Model for Sketch-to-Point Modeling">A Diffusion-ReFinement Model for Sketch-to-Point Modeling</a><time datetime="2023-02-04T15:11:53.000Z" title="发表于 2023-02-04 23:11:53">2023-02-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/27/Sketch-based-image-retrieval-via-siamese-convolutional-neural-network/" title="Sketch-based image retrieval via siamese convolutional neural network"><img src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Sketch-based image retrieval via siamese convolutional neural network"/></a><div class="content"><a class="title" href="/2023/01/27/Sketch-based-image-retrieval-via-siamese-convolutional-neural-network/" title="Sketch-based image retrieval via siamese convolutional neural network">Sketch-based image retrieval via siamese convolutional neural network</a><time datetime="2023-01-27T03:22:49.000Z" title="发表于 2023-01-27 11:22:49">2023-01-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/" title="DiffSketching: Sketch Control Image Synthesis with Diffusion Models"><img src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DiffSketching: Sketch Control Image Synthesis with Diffusion Models"/></a><div class="content"><a class="title" href="/2023/01/26/DiffSketching-Sketch-Control-Image-Synthesis-with-Diffusion-Models/" title="DiffSketching: Sketch Control Image Synthesis with Diffusion Models">DiffSketching: Sketch Control Image Synthesis with Diffusion Models</a><time datetime="2023-01-26T02:37:49.000Z" title="发表于 2023-01-26 10:37:49">2023-01-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/28/MUNIT%E5%A4%9A%E6%A8%A1%E6%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9B%BE%E6%83%B3%E5%88%B0%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="MUNIT多模态无监督图想到图像转换论文阅读"><img src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MUNIT多模态无监督图想到图像转换论文阅读"/></a><div class="content"><a class="title" href="/2022/12/28/MUNIT%E5%A4%9A%E6%A8%A1%E6%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%9B%BE%E6%83%B3%E5%88%B0%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="MUNIT多模态无监督图想到图像转换论文阅读">MUNIT多模态无监督图想到图像转换论文阅读</a><time datetime="2022-12-28T09:00:46.000Z" title="发表于 2022-12-28 17:00:46">2022-12-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/27/%E6%AF%95%E8%AE%BE%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%95%B4%E7%90%86/" title="毕设参考文献整理"><img src="https://wallroom.io/img/3840x2160/bg-b158248.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="毕设参考文献整理"/></a><div class="content"><a class="title" href="/2022/12/27/%E6%AF%95%E8%AE%BE%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%95%B4%E7%90%86/" title="毕设参考文献整理">毕设参考文献整理</a><time datetime="2022-12-27T03:34:44.000Z" title="发表于 2022-12-27 11:34:44">2022-12-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By kako523</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>